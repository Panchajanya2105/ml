{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fba2a50-082b-4541-a916-71820b5f9392",
   "metadata": {},
   "source": [
    "# Prg 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5920cfe-7ee4-4c87-b0d9-b062022a5ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e620c42f-ee93-4b16-9019-27c8e8e8642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'./housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75f007e-0e5e-4b71-8279-c447e6023fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34958247-1786-48a5-8a27-651a596ade09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6beb451-b590-47b1-9bb0-5dbf6f74fc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52676886-e450-4dff-a328-0b14a54ad914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7f0aa-a9ce-4cd6-bed3-42c137e7545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd10b377-2ddd-4bf9-aaa9-906eb33e0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['total_bedrooms'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ae362-167a-4b66-a1d0-b12da4bbe43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "df['total_bedrooms'].fillna(df['total_bedrooms'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ace8cb-2636-4d95-8df2-8124dd4dba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.iloc[:,2:7]:\n",
    "    df[i] = df[i].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42133724-7cc9-4609-a633-da23149e64f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eadd40-079b-4813-913b-eb0e1e185611",
   "metadata": {},
   "outputs": [],
   "source": [
    " df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed2f862-7c09-42c9-993e-0896f2829633",
   "metadata": {},
   "outputs": [],
   "source": [
    "Numerical = df.select_dtypes(include=[np.number]).columns\n",
    "print(Numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecda964a-30dc-4c81-ae3f-4d9abe195058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in Numerical:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df[col].plot(kind='hist', title=col, bins=60, edgecolor='black')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5540c825-2af7-472a-85bc-354d40b8d936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in Numerical:\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.boxplot(df[col], color='blue')\n",
    "    plt.title(col)\n",
    "    plt.ylabel(col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef18f921-2198-4470-82db-f2f7df05bed1",
   "metadata": {},
   "source": [
    "# Prg 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa05daf-9336-45d3-9b9f-9d32ffe0409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "# Load California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['Target'] = data.target # Adding the target variable (median house value)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9753a7b-aace-49d2-a837-c7ed53ce8878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Table of Meaning of Each Variable\n",
    "variable_meaning = {\n",
    "\"MedInc\": \"Median income in block group\",\n",
    "\"HouseAge\": \"Median house age in block group\",\n",
    "\"AveRooms\": \"Average number of rooms per household\",\n",
    "\"AveBedrms\": \"Average number of bedrooms per household\",\n",
    "\"Population\": \"Population of block group\",\n",
    "\"AveOccup\": \"Average number of household members\",\n",
    "\"Latitude\": \"Latitude of block group\",\n",
    "\"Longitude\": \"Longitude of block group\",\n",
    "\"Target\": \"Median house value (in $100,000s)\"\n",
    "}\n",
    "variable_df = pd.DataFrame(list(variable_meaning.items()), columns=[\"Feature\", \"Description\"])\n",
    "print(\"\\nVariable Meaning Table:\")\n",
    "print(variable_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce13fe-999d-4898-bd62-2124f33d7806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Basic Data Exploration\n",
    "print(\"\\nBasic Information about Dataset:\")\n",
    "print(df.info()) # Overview of dataset\n",
    "print(\"\\nFirst Five Rows of Dataset:\")\n",
    "print(df.head()) # Display first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae788200-9804-457b-a852-557254f8fba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summary Statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe()) # Summary statistics of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37ce009-ce76-4a87-a954-27f129ca8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_explanation = \"\"\"\n",
    "The summary statistics table provides key percentiles and other descriptive metrics\n",
    "- **25% (First Quartile - Q1):** This represents the value below which 25% of the d\n",
    "- **50% (Median - Q2):** This is the middle value when the data is sorted. It provi\n",
    "- **75% (Third Quartile - Q3):** This represents the value below which 75% of the d\n",
    "- These percentiles are useful for detecting skewness, data distribution, and ident\n",
    "\"\"\"\n",
    "print(\"\\nSummary Statistics Explanation:\")\n",
    "print(summary_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d121c88c-cda3-4099-9750-c3ab7d04ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "print(df.isnull().sum()) # Count of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3143e77b-d175-4ede-ac72-04b7ecd895fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histograms for distribution of features\n",
    "plt.figure(figsize=(12, 8))\n",
    "df.hist(figsize=(12, 8), bins=30, edgecolor='black')\n",
    "plt.suptitle(\"Feature Distributions\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b6bea-8f39-44d7-914b-63aff8586fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Boxplots for outlier detection\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Boxplots of Features to Identify Outliers\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c69c49-d191-400b-b69e-1fdae08a52c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562b975e-3ad6-4bf7-a479-ee72eff102ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pairplot to analyze feature relationships (only a subset for clarity)\n",
    "sns.pairplot(df[['MedInc', 'HouseAge', 'AveRooms', 'Target']], diag_kind='kde')\n",
    "plt.show()\n",
    "# Insights from Data Exploration\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"1. The dataset has\", df.shape[0], \"rows and\", df.shape[1], \"columns.\")\n",
    "print(\"2. No missing values were found in the dataset.\")\n",
    "print(\"3. Histograms show skewed distributions in some features like 'MedInc'.\")\n",
    "print(\"4. Boxplots indicate potential outliers in 'AveRooms' and 'AveOccup'.\")\n",
    "print(\"5. Correlation heatmap shows 'MedInc' has the highest correlation with house\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9fb940-fef5-4bbe-9d41-bcd221b0c222",
   "metadata": {},
   "source": [
    "# Prg 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b0a47-49af-4c03-9249-60ab070f4b30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "# Step 1: Load the Iris Dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data # Extracting feature matrix (4D data)\n",
    "y = iris.target # Extracting labels (0, 1, 2 representing three iris species)\n",
    "# Step 2: Standardizing the Data\n",
    "# PCA works best when data is standardized (mean = 0, variance = 1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Step 3: Calculating Covariance Matrix and Eigenvalues/Eigenvectors\n",
    "# The foundation of PCA is eigen decomposition of the covariance matrix\n",
    "cov_matrix = np.cov(X_scaled.T)\n",
    "print(cov_matrix)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\\n\", eigenvectors)\n",
    "# Step 4: Visualizing Data in 3D before PCA\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "colors = ['red', 'green', 'blue']\n",
    "labels = iris.target_names\n",
    "for i in range(len(colors)):\n",
    "    ax.scatter(X_scaled[y == i, 0], X_scaled[y == i, 1], X_scaled[y == i, 2], color=colors[i], label=labels[i])\n",
    "ax.set_xlabel('Sepal Length')\n",
    "ax.set_ylabel('Sepal Width')\n",
    "ax.set_zlabel('Petal Length')\n",
    "ax.set_title('3D Visualization of Iris Data Before PCA')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Step 5: Applying PCA using SVD (Singular Value Decomposition)\n",
    "# PCA internally relies on SVD, which decomposes a matrix into three parts: U, S, a\n",
    "U, S, Vt = np.linalg.svd(X_scaled, full_matrices=False)\n",
    "print(\"Singular Values:\", S)\n",
    "# Step 6: Applying PCA to Reduce Dimensionality to 2D\n",
    "# We reduce 4D data to 2D for visualization while retaining maximum variance\n",
    "pca = PCA(n_components=2) # We choose 2 components because we want to visualize\n",
    "X_pca = pca.fit_transform(X_scaled) # Transform data into principal components\n",
    "# Step 7: Understanding Variance Explained\n",
    "# PCA provides the percentage of variance retained in each principal component\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained Variance by PC1: {explained_variance[0]:.2f}\")\n",
    "print(f\"Explained Variance by PC2: {explained_variance[1]:.2f}\")\n",
    "# Step 8: Visualizing the Transformed Data\n",
    "# We plot the 2D representation of the Iris dataset after PCA transformation\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(colors)):\n",
    "    plt.scatter(X_pca[y == i, 0], X_pca[y == i, 1], color=colors[i], label=labels[i])\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('PCA on Iris Dataset (Dimensionality Reduction)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "            # Step 9: Visualizing Eigenvectors Superimposed on 3D Data\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i in range(len(colors)):\n",
    "    ax.scatter(X_scaled[y == i, 0], X_scaled[y == i, 1], X_scaled[y == i, 2], color=colors[i], label=labels[i])\n",
    "for i in range(3): # Plot first three eigenvectors\n",
    "    ax.quiver(0, 0, 0, eigenvectors[i, 0], eigenvectors[i, 1], eigenvectors[i, 2], color='black', length=1)\n",
    "ax.set_xlabel('Sepal Length')\n",
    "ax.set_ylabel('Sepal Width')\n",
    "ax.set_zlabel('Petal Length')\n",
    "ax.set_title('3D Data with Eigenvectors')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Recap:\n",
    "# - The Iris dataset is historically important for testing classification models.\n",
    "# - We standardized the data to ensure fair comparison across features.\n",
    "# - We calculated the covariance matrix, eigenvalues, and eigenvectors.\n",
    "# - PCA is built on SVD, which decomposes data into important components.\n",
    "# - We visualized the original 3D data and superimposed eigenvectors.\n",
    "# - We applied PCA to reduce the dimensionality from 4D to 2D.\n",
    "# - Finally, we visualized the transformed data in 2D space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32cc55-2910-4e0a-ad48-c855cc8cba48",
   "metadata": {},
   "source": [
    "# Prg 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1fac4-6b70-4209-9957-59dcf96344bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r\"./training_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32aa11-2659-47ee-ae84-aa80520a94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd0e19-5497-4289-87e8-4eb7b7e2396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_s_algorithm(data):\n",
    "    \"\"\"Implements the Find-S algorithm to find the most specific hypothesis.\"\"\"\n",
    "    # Extract feature columns and target column\n",
    "    attributes = data.iloc[:, :-1].values # All columns except last\n",
    "    target = data.iloc[:, -1].values # Last column (class labels)\n",
    "    # Step 1: Initialize hypothesis with first positive example\n",
    "    for i in range(len(target)):\n",
    "        if target[i] == \"Yes\": # Consider only positive examples\n",
    "            hypothesis = attributes[i].copy()\n",
    "            break\n",
    "    # Step 2: Update hypothesis based on other positive examples\n",
    "    for i in range(len(target)):\n",
    "        if target[i] == \"Yes\":\n",
    "            for j in range(len(hypothesis)):\n",
    "                if hypothesis[j] != attributes[i][j]:\n",
    "                    hypothesis[j] = '?' # Generalize inconsistent attributes\n",
    "    return hypothesis\n",
    "# Run Find-S Algorithm\n",
    "final_hypothesis = find_s_algorithm(data)\n",
    "# Print the learned hypothesis\n",
    "print(\"Most Specific Hypothesis:\", final_hypothesis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651608b5-e61c-4e4b-98ca-dc00b586bc29",
   "metadata": {},
   "source": [
    "# Prg 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716aee20-3a49-49b7-9c09-096cb43d699a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cce77c-d79f-4904-a43b-49c4fb94b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate dataset\n",
    "np.random.seed(42)\n",
    "values = np.random.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba7a33-28fa-494a-9869-7ea2f40dad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in values[:50]:\n",
    "    if i <=0.5:\n",
    "        labels.append('Class1')\n",
    "    else:\n",
    "        labels.append('Class2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4f429-3e58-447f-8b17-b74b62d9f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels += [None] * 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f85440f-b20b-4546-beb9-bafa0c301202",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9164cdb9-7de4-433b-ae62-e95ebbd33178",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Point\": [f\"x{i+1}\" for i in range(100)],\n",
    "    \"Value\": values,\n",
    "    \"Label\": labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982335a4-e403-4ee5-8a7a-38cbc4448fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622e0b8-4ca6-457e-afbc-90909fb54e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7af27f9-cf74-4f11-9674-7a7b3914f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of Meaning of Each Variable\n",
    "variable_meaning = {\n",
    "    \"Point\": \"The point number\",\n",
    "    \"Value\": \"The value of the point\",\n",
    "    \"Label\": \"The class of the point\"\n",
    "}\n",
    "variable_df = pd.DataFrame(list(variable_meaning.items()), columns=[\"Feature\", \"Description\"])\n",
    "print(\"\\nVariable Meaning Table:\")\n",
    "print(variable_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2418897-3f60-4c17-8666-082959d703b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9201e3-9698-4acf-b9c0-54bc1263c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a3b7ad-e975-4e77-b0c2-da2fb32ba415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Data Exploration\n",
    "print(\"\\nBasic Information about Dataset:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ffed8-aaac-46c3-84ff-b281325e3fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary Statistics:\")\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e452b48e-4255-40ba-b44a-1607c5816825",
   "metadata": {},
   "outputs": [],
   "source": [
    "Summary_Statistics=\"\"\"\n",
    "- The 'Value' column has a mean of approximately 0.47, indicating that the values a\n",
    "- The standard deviation of the 'Value' column is approximately 0.29, showing a mod\n",
    "- The minimum value in the 'Value' column is approximately 0.0055, and the maximum\n",
    "- The first quartile (25th percentile) is approximately 0.19, the median (50th perc\"\"\"\n",
    "print(Summary_Statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95d5c6-d378-442f-a211-bc0413d7292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing Values in Each Column:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a54299-6e9d-48f6-833a-693953cfe17b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get numeric columns\n",
    "num_col = df.select_dtypes(include=['int', 'float']).columns\n",
    "# Histograms for distribution of features\n",
    "df[num_col].hist(figsize=(12, 8), bins=30, edgecolor='black')\n",
    "# Title and labels\n",
    "plt.suptitle(\"Feature Distributions\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a038702-758b-4c2b-adeb-45e3b4cef71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference for the above graph\n",
    "inference = \"\"\"\n",
    "- The histograms for the distribution of features show that the values are uniforml\n",
    "- This is expected as the values were generated using a uniform random distribution\n",
    "- There are no significant outliers or skewness in the data, indicating that the da\n",
    "\"\"\"\n",
    "print(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255d77cd-0f04-484a-80db-d8a8a00f5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into labeled and unlabeled\n",
    "labeled_df = df[df[\"Label\"].notna()]\n",
    "X_train = labeled_df[[\"Value\"]]\n",
    "y_train = labeled_df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95356b83-82eb-4fa6-8753-961e0861e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_df = df[df[\"Label\"].isna()]\n",
    "X_test = unlabeled_df[[\"Value\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a395481-7aa5-4ebf-927d-be567146e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate true labels for testing (for accuracy calculation)\n",
    "true_labels = [\"Class1\" if x <= 0.5 else \"Class2\" for x in values[50:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c19df9-4064-46af-b7d4-1b0ed31308f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Perform KNN classification for different values of k\n",
    "k_values = [1, 2, 3, 4, 5, 20, 30]\n",
    "results = {}\n",
    "accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698c634-5db9-47e6-bc14-c2e347ec5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    predictions = knn.predict(X_test)\n",
    "    results[k] = predictions\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions) * 100\n",
    "    accuracies[k] = accuracy\n",
    "    print(f\"Accuracy for k={k}: {accuracy:.2f}%\")\n",
    "    # Assign predictions back to the DataFrame for this k\n",
    "    unlabeled_df[f\"Label_k{k}\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229cc1e-e99b-4940-96bd-8f21bff21701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference for the KNN classification results\n",
    "knn_inference = \"\"\"\n",
    "- The KNN classification was performed for different values of k: 1, 2, 3, 4, 5, 20\n",
    "- The accuracy of the classification varied with the value of k.\n",
    "- For smaller values of k (1, 2, 3, 4, 5), the accuracy was relatively high, indica\n",
    "- As the value of k increased to 20 and 30, the accuracy decreased, suggesting that\n",
    "- This is expected as higher values of k can lead to over-smoothing, where the mode\n",
    "- Overall, the KNN classifier performed well for smaller values of k, with the high\n",
    "\"\"\"\n",
    "print(knn_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1266e-c670-455a-8834-775500a95ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39852281-4b27-45fa-9c7c-2bad402746f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = unlabeled_df.drop(columns=['Label'], axis=1)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7665c8-82d6-4cf6-abcc-55e5653989a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display accuracies\n",
    "print(\"\\nAccuracies for different k values:\")\n",
    "for k, acc in accuracies.items():\n",
    "    print(f\"k={k}: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7e21a4-2ee6-459e-aaa4-bdb5f830b4f1",
   "metadata": {},
   "source": [
    "# Prg 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81858063-fe92-4e0c-bbf1-1061692897f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def gaussian_kernel(x, x_query, tau):\n",
    "    return np.exp(- (x - x_query) ** 2 / (2 * tau ** 2))\n",
    "def locally_weighted_regression(X, y, x_query, tau):\n",
    "    X_b = np.c_[np.ones(len(X)), X] # Add bias term (Intercept)\n",
    "    x_query_b = np.array([1, x_query]) # Query point with bias term\n",
    "    W = np.diag(gaussian_kernel(X, x_query, tau)) # Compute weights\n",
    "    # Compute theta: (X^T W X)^-1 X^T W y\n",
    "    theta = np.linalg.inv(X_b.T @ W @ X_b) @ X_b.T @ W @ y\n",
    "    return x_query_b @ theta # Return prediction\n",
    "# Dataset\n",
    "X = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([1, 2, 1.3, 3.75, 2.25])\n",
    "# Query point\n",
    "x_query = 3 # Point at which we perform LWR\n",
    "# Bandwidth parameter\n",
    "tau = 1.0\n",
    "# Compute prediction\n",
    "y_pred = locally_weighted_regression(X, y, x_query, tau)\n",
    "# Visualizing\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.scatter(x_query, y_pred, color='red', label=f'Prediction at x={x_query}')\n",
    "# Plot weights effect\n",
    "weights = gaussian_kernel(X, x_query, tau)\n",
    "for i in range(len(X)):\n",
    "    plt.plot([X[i], X[i]], [y[i], y[i] - weights[i]], 'k-', lw=1)\n",
    "    plt.scatter(X[i], y[i], s=weights[i] * 200, color='green', alpha=0.5)\n",
    "plt.title(\"Locally Weighted Regression (LWR)\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ac6bfa-a689-49f9-9eb8-e7407eae606b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def gaussian_kernel(x, x_query, tau):\n",
    "    return np.exp(- (x - x_query) ** 2 / (2 * tau ** 2))\n",
    "def locally_weighted_regression(X, y, x_query, tau):\n",
    "    X_b = np.c_[np.ones(len(X)), X] # Add bias term (Intercept)\n",
    "    x_query_b = np.array([1, x_query]) # Query point with bias term\n",
    "    W = np.diag(gaussian_kernel(X, x_query, tau)) # Compute weights\n",
    "    # Compute theta: (X^T W X)^-1 X^T W y\n",
    "    theta = np.linalg.inv(X_b.T @ W @ X_b) @ X_b.T @ W @ y\n",
    "    return x_query_b @ theta # Return prediction\n",
    "# Complex Dataset\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y = np.array([1, 3, 2, 4, 3.5, 5, 6, 7, 6.5, 8])\n",
    "# Query points for LWR\n",
    "X_query = np.linspace(1, 10, 100)\n",
    "tau = 1.0 # Bandwidth parameter\n",
    "# Compute LWR predictions\n",
    "y_lwr = np.array([locally_weighted_regression(X, y, x_q, tau) for x_q in X_query])\n",
    "# Simple Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "X_reshaped = X.reshape(-1, 1)\n",
    "lin_reg.fit(X_reshaped, y)\n",
    "y_lin = lin_reg.predict(X_query.reshape(-1, 1))\n",
    "# Visualizing\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_query, y_lin, color='black', linestyle='dashed', label='Simple Linear Regression')\n",
    "plt.plot(X_query, y_lwr, color='red', label='Locally Weighted Regression')\n",
    "plt.title(\"Comparison: Simple Linear Regression vs. Locally Weighted Regression\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802bf59b-31aa-41b0-8b2d-f8d1b779350c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "def gaussian_kernel(x, x_query, tau):\n",
    "    return np.exp(- (x - x_query) ** 2 / (2 * tau ** 2))\n",
    "def locally_weighted_regression(X, y, x_query, tau):\n",
    "    X_b = np.c_[np.ones(len(X)), X] # Add bias term (Intercept)\n",
    "    x_query_b = np.array([1, x_query]) # Query point with bias term\n",
    "    W = np.diag(gaussian_kernel(X, x_query, tau)) # Compute weights\n",
    "    # Compute theta using pseudo-inverse to avoid singular matrix error\n",
    "    theta = np.linalg.pinv(X_b.T @ W @ X_b) @ X_b.T @ W @ y\n",
    "    return x_query_b @ theta # Return prediction\n",
    "# Complex Dataset\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "y = np.array([1, 3, 2, 4, 3.5, 5, 6, 7, 6.5, 8])\n",
    "# Query points for LWR\n",
    "X_query = np.linspace(1, 10, 100)\n",
    "tau_values = [0.1, 0.5, 1.0, 5.0, 10.0] # Different bandwidth values\n",
    "# Simple Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "X_reshaped = X.reshape(-1, 1)\n",
    "lin_reg.fit(X_reshaped, y)\n",
    "y_lin = lin_reg.predict(X_query.reshape(-1, 1))\n",
    "# Visualizing\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X, y, color='blue', label='Data Points')\n",
    "plt.plot(X_query, y_lin, color='black', linestyle='dashed', label='Simple Linear Regression')\n",
    "# Plot LWR for different tau values\n",
    "colors = ['red', 'green', 'purple', 'orange', 'brown']\n",
    "for tau, color in zip(tau_values, colors):\n",
    "    y_lwr = np.array([locally_weighted_regression(X, y, x_q, tau) for x_q in X_query])\n",
    "    plt.plot(X_query, y_lwr, color=color, label=f'LWR (τ={tau})')\n",
    "plt.title(\"Effect of Different τ Values in Locally Weighted Regression\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0db0540-bce0-476b-93f9-74af43839db8",
   "metadata": {},
   "source": [
    "# Prg 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f094f73-96e1-44c5-912e-da9f8a124b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac22c6-e04b-480c-b0dc-4d0ba638d394",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'./Bostonhousingdataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc44e2-2f49-48f5-83e8-f752b9a0f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32edece0-1cda-4337-9283-fec1e9c14929",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b020b-9a6d-403c-b7ff-0b657be08176",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e99231-f7be-4120-a535-a2eab574f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8a773-68de-4c85-9c73-9bdf0140ab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.CHAS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ab821-d1f0-4952-a1e0-4c31fc2456ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ZN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95991fa4-930a-470e-814d-12fd5371c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ee8609-bbf1-4ad8-aacf-2b6fb7acfc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d1cc00-692b-466e-a974-eb68b2c643f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8739a893-bd5b-4242-89d8-17bf83642ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CRIM'].fillna(df['CRIM'].mean(), inplace=True)\n",
    "df['ZN'].fillna(df['ZN'].mean(), inplace=True)\n",
    "df['CHAS'].fillna(df['CHAS'].mode()[0], inplace=True)\n",
    "df['INDUS'].fillna(df['INDUS'].mean(), inplace=True)\n",
    "df['AGE'].fillna(df['AGE'].median(), inplace=True) # Median is often preferred for\n",
    "df['LSTAT'].fillna(df['LSTAT'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee38d716-8c09-4a08-8187-d882b8ba3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba635d70-c2af-4c81-91ee-f51b98db5cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd0ac0b-f893-43d6-819a-585c5d310e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CHAS'] = df['CHAS'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55937b0-74ad-4e83-95d4-6c8b210ed93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf5988-6240-4e45-a3a5-e638f4e985d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.columns:\n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    df[i].hist(bins=20, alpha=0.5, color='b',edgecolor='black')\n",
    "    \n",
    "    plt.title(f'Histogram of {i}')\n",
    "    plt.xlabel(i)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(df[i], vert=False)\n",
    "    \n",
    "    plt.title(f'Boxplot of {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52446f-54a0-4c9e-8f8e-05fed4538d8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr = df.corr(method='pearson')\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.xticks(rotation=90, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.title(\"Correlation Matrix Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe8aa0-1074-465c-a9f9-a8aa2d7dcdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('MEDV', axis=1) # All columns except 'MEDV'\n",
    "y = df['MEDV'] # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf2a97-a67a-474b-8b48-f20fbfeb1fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scale = StandardScaler()\n",
    "X_scaled = scale.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa03235-895a-4c57-9b3e-4bb35ad3d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled , y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f3e914-199c-483e-9b8c-bf05c0bfb907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a22ff-61ce-412c-92cd-644e89e22002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e42c30-cc30-4c05-bad5-4b0e35f82827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mse)\n",
    "# Calculate R-squared value\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40307978-e7ab-41d7-8e48-d9b78c7a0ee4",
   "metadata": {},
   "source": [
    "# Prg 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045e898-b142-42d2-b9b4-b8673212cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238cda4-e276-4243-9553-0fdcd488b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'./WisconsinBreastCancerdataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a1f34-f7b3-4e0b-94e4-2e6da6e4ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c63e9-8998-432d-b8d9-d3b9b6588909",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab81090-a891-4880-924d-0936cb855250",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659162e-caec-4c94-8365-ffb02e07efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a99419f-92b5-45c3-81f3-0fac4a0c7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.diagnosis.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef3acb4-d961-4663-94c5-85b1633f592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678310ec-9331-41d5-8d4a-1ce5ef5d9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(['id', 'Unnamed: 32'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6683dacd-df05-498d-a1f8-6ccb91f12f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].map({'M':1, 'B':0}) # Malignant:1, Benign:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee1d37-c7d3-4eed-b52e-01bbc9747f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468cef0-f5d4-4c9c-976c-3b096ab2a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('diagnosis', axis=1) # Drop the 'diagnosis' column (target)\n",
    "y = df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d03057-036e-4725-ba5d-220b4eb1bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79c1431-30dd-41a2-b7c8-1acc98929bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the decision tree model\n",
    "model = DecisionTreeClassifier(criterion='entropy') #criteria = gini, entropy\n",
    "model.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a382a6-ebe8-4195-99a7-d6c932fd060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Function to calculate entropy\n",
    "\n",
    "def entropy(column):\n",
    "    counts = column.value_counts()\n",
    "    probabilities = counts / len(column)\n",
    "    return -sum(probabilities * probabilities.apply(math.log2))\n",
    "# Function to calculate conditional entropy\n",
    "def conditional_entropy(data, X, target):\n",
    "    feature_values = data[X].unique() # Corrected: use .unique() on the series\n",
    "    weighted_entropy = 0\n",
    "    for value in feature_values:\n",
    "        subset = data[data[feature] == value]\n",
    "        weighted_entropy += (len(subset) / len(data)) * entropy(subset[target])\n",
    "    return weighted_entropy\n",
    "# Function to calculate information gain\n",
    "def information_gain(data, X, target):\n",
    "    total_entropy = entropy(data[target])\n",
    "    feature_conditional_entropy = conditional_entropy(data, X, target)\n",
    "    return total_entropy - feature_conditional_entropy\n",
    "# Calculate information gain for each feature\n",
    "for feature in X:\n",
    "    ig = information_gain(df,feature,'diagnosis')\n",
    "    print(f\"Information Gain for {feature}: {ig}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09e8af-2e0f-462c-a2f9-5949c2dd2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Decision Tree (optional)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(model, filled=True, feature_names=X.columns, class_names=['Benign', 'Malignant'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2302b00-0a1e-4baa-8d2f-95d7d2b1be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347eabc9-4e5a-4e30-ad27-ba7dc8a4493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce5152a-280f-4ae2-8534-531252ef71c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263a03a-bf1a-497a-ab1d-21aee69f0efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = [[12.5, 19.2, 80.0, 500.0, 0.085, 0.1, 0.05, 0.02, 0.17, 0.06,\n",
    "    0.4, 1.0, 2.5, 40.0, 0.006, 0.02, 0.03, 0.01, 0.02, 0.003,\n",
    "    16.0, 25.0, 105.0, 900.0, 0.13, 0.25, 0.28, 0.12, 0.29, 0.08]]\n",
    "y_pred = model.predict(new)\n",
    "# Output the prediction (0 = Benign, 1 = Malignant)\n",
    "if y_pred[0] == 0:\n",
    "    print(\"Prediction: Benign\")\n",
    "else:\n",
    "    print(\"Prediction: Malignant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b689bdb-407d-4883-a578-090f5ec8c613",
   "metadata": {},
   "source": [
    "# Prg 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32346a93-f4ff-4e16-ae32-e2298a4486a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b582257-3851-491d-87e4-eaee2da32f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "data = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5b0b5-265e-4889-9e1b-2c50ea240213",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc8a8b-797f-4456-b9fe-9db994b782ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Shape:\", data.data.shape)\n",
    "print(\"Target Shape:\", data.target.shape)\n",
    "print(\"There are {} unique persons in the dataset\".format(len(np.unique(data.target))))\n",
    "print(\"Size of each image is {}x{}\".format(data.images.shape[1],data.images.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a69f3-1453-4117-9ab7-261e954e49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_faces(images, target, top_n):\n",
    "    # Ensure the number of images does not exceed available data\n",
    "    top_n = min(top_n, len(images))\n",
    "    # Set up figure size based on the number of images\n",
    "    grid_size = int(np.ceil(np.sqrt(top_n)))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.2, wspace=0.2)\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        if i < top_n:\n",
    "            ax.imshow(images[i], cmap='bone')\n",
    "            ax.axis('off')\n",
    "            ax.text(2, 12, str(target[i]), fontsize=9, color='red')\n",
    "            ax.text(2, 55, f\"face: {i}\", fontsize=9, color='blue')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce36176d-dab6-4f63-bb9a-bbf1f997b15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_faces(data.images,data.target,400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6010dc-e4da-4fc0-bca1-18602fdba76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us extract unique charaters present in dataset\n",
    "def display_unique_faces(pics):\n",
    "    fig = plt.figure(figsize=(24, 10)) # Set figure size\n",
    "    columns, rows = 10, 4 # Define grid dimensions\n",
    "    # Loop through grid positions and plot each image\n",
    "    for i in range(1, columns * rows + 1):\n",
    "        img_index = 10 * i - 1 # Calculate the image index\n",
    "        if img_index < pics.shape[0]: # Check for valid image index\n",
    "            img = pics[img_index, :, :]\n",
    "            ax = fig.add_subplot(rows, columns, i)\n",
    "            ax.imshow(img, cmap='gray')\n",
    "            ax.set_title(f\"Person {i}\", fontsize=14)\n",
    "            ax.axis('off')\n",
    "    plt.suptitle(\"There are 40 distinct persons in the dataset\", fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188104fe-88fc-4209-8f37-f8d5566337f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_unique_faces(data.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f51178-7a86-4876-9e2b-52e7121abb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.data\n",
    "Y = data.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state=42)\n",
    "print(\"x_train: \",x_train.shape)\n",
    "print(\"x_test: \",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7948163-1c86-45c5-aad8-75f7bc9a9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# Train the model\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train, y_train)\n",
    "# Predict the test set results\n",
    "y_pred = nb.predict(x_test)\n",
    "# Calculate accuracy\n",
    "nb_accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "# Display accuracy result\n",
    "print(f\"Naive Bayes Accuracy: {nb_accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8078c4-46b3-49a5-8d67-565644b8e5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "# Initialize and fit Multinomial Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)\n",
    "# Predict the test set results\n",
    "y_pred = nb.predict(x_test)\n",
    "# Calculate accuracy\n",
    "accuracy = round(accuracy_score(y_test, y_pred) * 100, 2)\n",
    "print(f\"Multinomial Naive Bayes Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ac788-6f0d-4f2d-be48-97f2608a5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of misclassified images\n",
    "misclassified_idx = np.where(y_pred != y_test)[0]\n",
    "num_misclassified = len(misclassified_idx)\n",
    "# Print the number of misclassified images and accuracy\n",
    "print(f\"Number of misclassified images: {num_misclassified}\")\n",
    "print(f\"Total images in test set: {len(y_test)}\")\n",
    "print(f\"Accuracy: {round((1 - num_misclassified / len(y_test)) * 100, 2)}%\")\n",
    "# Visualize some of the misclassified images\n",
    "n_misclassified_to_show = min(num_misclassified, 5) # Show up to 5 misclassified i\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(n_misclassified_to_show):\n",
    "    idx = misclassified_idx[i]\n",
    "    plt.subplot(1, n_misclassified_to_show, i + 1)\n",
    "    plt.imshow(x_test[idx].reshape(64, 64), cmap='gray')\n",
    "    plt.title(f\"True: {y_test[idx]}, Pred: {y_pred[idx]}\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b8fd4-5bad-4483-b833-1a548535ec20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Binarize the test labels\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "# Get predicted probabilities for each class\n",
    "y_pred_prob = nb.predict_proba(x_test)\n",
    "# Calculate and print AUC for each class\n",
    "for i in range(y_test_bin.shape[1]):\n",
    "    roc_auc = roc_auc_score(y_test_bin[:, i], y_pred_prob[:, i])\n",
    "    print(f\"Class {i} AUC: {roc_auc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f70211-dbec-4167-846b-25b60b662e16",
   "metadata": {},
   "source": [
    "# Prg 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1311cb-8259-4292-8bd2-24cd5942f2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c391091-663e-4e3a-8568-d9bc8eceec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"./WisconsinBreastCancerdataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e9ff7-d39c-49a8-8f10-74a3082d3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa350bc-168a-4813-8a29-d0a1b916d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a963b1b4-51c8-4da8-bf2d-73cf3674144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f035530-fd25-43cb-b70d-780e983b2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.diagnosis.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d5cff3-a695-4a5a-8e5e-2f6d02cbfdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83429f6-fbaa-4a10-834b-2d4f00151632",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c442f-ddab-495b-a0d2-8968d1cd5c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(['id', 'Unnamed: 32'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865298d6-03bd-471c-8af4-652b783dcfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].map({'M':1, 'B':0}) # Malignant:1, Benign:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57767766-55ce-4e85-b532-74e12885dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c7256-723e-4ed6-a86d-7cf356aad284",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped the Diagnosis (target) since clustering is unsupervised.\n",
    "df.drop(columns=[\"diagnosis\"], inplace=True) # Removing Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd140a41-e99a-493a-99cf-76fcfe1ae2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21b3c7-d450-4530-bfae-ef6831b94d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for Dimensionality Reduction\n",
    "pca = PCA(n_components=2) # Reduce to 2 dimensions for visualization\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae16491-b4b0-4e23-8d92-4b62f5a2d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check explained variance ratio\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "total_explained_variance = np.sum(explained_variance)\n",
    "print(f\"Variance explained by PC1: {explained_variance[0]:.4f}\")\n",
    "print(f\"Variance explained by PC2: {explained_variance[1]:.4f}\")\n",
    "print(f\"Total variance explained by first 2 components: {total_explained_variance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482af3e-5287-43b6-b761-3c64f21d63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the Elbow Method to determine the optimal number of clusters\n",
    "wcss = [] # Within-Cluster Sum of Squares\n",
    "K_range = range(1, 11)\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_pca)\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7832328f-86f1-4c1d-a884-95440d3c45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Elbow Method Graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K_range, wcss, marker=\"o\", linestyle=\"-\")\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.title(\"Elbow Method to Find Optimal k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8d931-bb70-4fdc-800a-919c1abe465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply K-Means Clustering with the optimal k (usually where elbow occurs, k=2)\n",
    "optimal_k = 2\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374f2cc4-d949-4543-a09d-4886f757597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Visualize the Clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap=\"viridis\", alpha=0.6)\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=200, c='red', marker='X', label='Centroids')\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.title(\"K-Means Clustering after PCA\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd15eb9-8a67-49f6-b80b-24c9a1e210ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
